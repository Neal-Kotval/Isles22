{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "aamgwIy2lxHt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RMdd12oqwVd",
        "outputId": "bd9affd1-830c-4f2c-c8cb-c112fc6260d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.10/dist-packages (0.10.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.25.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (71.0.4)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2024.7.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import PIL\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import data\n",
        "from skimage.util import montage\n",
        "import skimage.transform as skTrans\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "!pip install nibabel nilearn\n",
        "import nilearn as nl\n",
        "import nibabel as nib\n",
        "import nilearn.plotting as nlplt\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import CSVLogger\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow.keras as tfk\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants\n"
      ],
      "metadata": {
        "id": "OJ02XaNNl4Zb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-VrUI9SqwVe",
        "outputId": "9ececf83-ea5d-4e91-830a-922aada7c229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "TRAIN_DATASET_PATH='/content/drive/My Drive/data/isles/rawdata/'\n",
        "VALIDATION_DATASET_PATH=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgVTJGWfqwVe"
      },
      "outputs": [],
      "source": [
        "SEGMENT_CLASSES = {\n",
        "    0 : 'NOT LESION',\n",
        "    1 : 'LESION'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71WdJWyvqwVf"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=128\n",
        "NR_SLICES = 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict()\n",
        "\n",
        "config[\"data_folder\"] = os.path.abspath(\"/content/drive/My Drive/data/isles/rawdata/\") #path to folder containing the training data\n",
        "config[\"model_file\"] = os.path.join(config[\"model_folder\"], \"model.h5\")\n",
        "config[\"wieghts_file_bestval\"] = os.path.join(config[\"model_folder\"], \"BEST_val.h5\")\n",
        "config[\"wieghts_file_lasttrain\"] = os.path.join(config[\"model_folder\"], \"LAST_train.h5\")\n",
        "config[\"training_file\"] = os.path.join(config[\"output_folder\"], \"training_ids.pkl\")\n",
        "config[\"validation_file\"] = os.path.join(config[\"output_folder\"], \"validation_ids.pkl\")\n",
        "config[\"logging_file\"] = os.path.join(config[\"output_folder\"], \"training.log\")\n",
        "config[\"overwrite\"] = False  # If True, will overwite previous files. If False, will use previously written files.\n",
        "\n",
        "# model settings\n",
        "config[\"input_size\"] = (IMG_SIZE,IMG_SIZE) # size of image (x,y)\n",
        "config[\"nr_slices\"] = (NR_SLICES,) # all inputs will be resliced to this number of slices (z axis), must be power of 2\n",
        "config[\"modalities\"] = [\"dwi\"]\n",
        "config[\"mean\"] = [37.3555097]#preprocessed\n",
        "config[\"std\"] = [84.6591447]#preprocessed\n",
        "\n",
        "# Mean:  [37.3555097]\n",
        "# STD:  [84.6591447]\n",
        "\n",
        "config[\"labels\"] = 1 # the label numbers on the input image (exclude background)\n",
        "\n",
        "# training settings\n",
        "config[\"batch_size\"] = 16\n",
        "config[\"n_epochs\"] = 200  # cutoff the training after this many epochs\n",
        "config[\"initial_learning_rate\"] = 5e-3\n",
        "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
        "config[\"test_size\"] = 0.2  # portion of the data that will be used for validation"
      ],
      "metadata": {
        "id": "4gw1SbJNnVBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Metrics\n"
      ],
      "metadata": {
        "id": "EttebPOvl7wF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Mpal-peqwVf"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    class_num = 2\n",
        "    for i in range(class_num):\n",
        "        y_true_f = keras.layers.Flatten()(y_true[:,:,:,i])\n",
        "        y_pred_f = keras.layers.Flatten()(y_pred[:,:,:,i])\n",
        "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "        loss = ((2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth))\n",
        "        if i == 0:\n",
        "            total_loss = loss\n",
        "        else:\n",
        "            total_loss = total_loss + loss\n",
        "    total_loss = total_loss / class_num\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "vuKExo7pmADR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOUU8zivMtNU"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, kernels, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
        "               is_bn=True, is_relu=True, n=2):\n",
        "    \"\"\" Custom function for conv2d:\n",
        "        Apply  3*3 convolutions with BN and relu.\n",
        "    \"\"\"\n",
        "    for i in range(1, n + 1):\n",
        "        x = tfk.layers.Conv2D(filters=kernels, kernel_size=kernel_size,\n",
        "                            padding=padding, strides=strides,\n",
        "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "                            kernel_initializer=tfk.initializers.he_normal(seed=5))(x)\n",
        "        if is_bn:\n",
        "            x = tfk.layers.BatchNormalization()(x)\n",
        "        if is_relu:\n",
        "            x = tfk.activations.relu(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFZPuTp4qwVg"
      },
      "outputs": [],
      "source": [
        "# source https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
        "\n",
        "\n",
        "def unet3plus(input_shape, output_channels):\n",
        "    \"\"\" UNet3+ base model \"\"\"\n",
        "    filters = [8, 16, 32, 64, 128]\n",
        "\n",
        "    input_layer = tfk.layers.Input(\n",
        "        shape=input_shape,\n",
        "        name=\"input_layer\"\n",
        "    )  # 320*320*3\n",
        "\n",
        "    \"\"\" Encoder\"\"\"\n",
        "    # block 1\n",
        "    e1 = conv_block(input_layer, filters[0])  # 320*320*64\n",
        "\n",
        "    # block 2\n",
        "    e2 = tfk.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 160*160*64\n",
        "    e2 = conv_block(e2, filters[1])  # 160*160*128\n",
        "\n",
        "    # block 3\n",
        "    e3 = tfk.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 80*80*128\n",
        "    e3 = conv_block(e3, filters[2])  # 80*80*256\n",
        "\n",
        "    # block 4\n",
        "    e4 = tfk.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 40*40*256\n",
        "    e4 = conv_block(e4, filters[3])  # 40*40*512\n",
        "\n",
        "    # block 5\n",
        "    # bottleneck layer\n",
        "    e5 = tfk.layers.MaxPool2D(pool_size=(2, 2))(e4)  # 20*20*512\n",
        "    e5 = conv_block(e5, filters[4])  # 20*20*1024\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    cat_channels = filters[0]\n",
        "    cat_blocks = len(filters)\n",
        "    upsample_channels = cat_blocks * cat_channels\n",
        "\n",
        "    \"\"\" d4 \"\"\"\n",
        "    e1_d4 = tfk.layers.MaxPool2D(pool_size=(8, 8))(e1)  # 320*320*64  --> 40*40*64\n",
        "    e1_d4 = conv_block(e1_d4, cat_channels, n=1)  # 320*320*64  --> 40*40*64\n",
        "\n",
        "    e2_d4 = tfk.layers.MaxPool2D(pool_size=(4, 4))(e2)  # 160*160*128 --> 40*40*128\n",
        "    e2_d4 = conv_block(e2_d4, cat_channels, n=1)  # 160*160*128 --> 40*40*64\n",
        "\n",
        "    e3_d4 = tfk.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 80*80*256  --> 40*40*256\n",
        "    e3_d4 = conv_block(e3_d4, cat_channels, n=1)  # 80*80*256  --> 40*40*64\n",
        "\n",
        "    e4_d4 = conv_block(e4, cat_channels, n=1)  # 40*40*512  --> 40*40*64\n",
        "\n",
        "    e5_d4 = tfk.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)  # 80*80*256  --> 40*40*256\n",
        "    e5_d4 = conv_block(e5_d4, cat_channels, n=1)  # 20*20*1024  --> 20*20*64\n",
        "\n",
        "    d4 = tfk.layers.concatenate([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n",
        "    d4 = conv_block(d4, upsample_channels, n=1)  # 40*40*320  --> 40*40*320\n",
        "\n",
        "    \"\"\" d3 \"\"\"\n",
        "    e1_d3 = tfk.layers.MaxPool2D(pool_size=(4, 4))(e1)  # 320*320*64 --> 80*80*64\n",
        "    e1_d3 = conv_block(e1_d3, cat_channels, n=1)  # 80*80*64 --> 80*80*64\n",
        "\n",
        "    e2_d3 = tfk.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 160*160*256 --> 80*80*256\n",
        "    e2_d3 = conv_block(e2_d3, cat_channels, n=1)  # 80*80*256 --> 80*80*64\n",
        "\n",
        "    e3_d3 = conv_block(e3, cat_channels, n=1)  # 80*80*512 --> 80*80*64\n",
        "\n",
        "    e4_d3 = tfk.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)  # 40*40*320 --> 80*80*320\n",
        "    e4_d3 = conv_block(e4_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    e5_d3 = tfk.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)  # 20*20*320 --> 80*80*320\n",
        "    e5_d3 = conv_block(e5_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    d3 = tfk.layers.concatenate([e1_d3, e2_d3, e3_d3, e4_d3, e5_d3])\n",
        "    d3 = conv_block(d3, upsample_channels, n=1)  # 80*80*320 --> 80*80*320\n",
        "\n",
        "    \"\"\" d2 \"\"\"\n",
        "    e1_d2 = tfk.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 320*320*64 --> 160*160*64\n",
        "    e1_d2 = conv_block(e1_d2, cat_channels, n=1)  # 160*160*64 --> 160*160*64\n",
        "\n",
        "    e2_d2 = conv_block(e2, cat_channels, n=1)  # 160*160*256 --> 160*160*64\n",
        "\n",
        "    d3_d2 = tfk.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d3)  # 80*80*320 --> 160*160*320\n",
        "    d3_d2 = conv_block(d3_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d4_d2 = tfk.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d4)  # 40*40*320 --> 160*160*320\n",
        "    d4_d2 = conv_block(d4_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    e5_d2 = tfk.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)  # 20*20*320 --> 160*160*320\n",
        "    e5_d2 = conv_block(e5_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d2 = tfk.layers.concatenate([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n",
        "    d2 = conv_block(d2, upsample_channels, n=1)  # 160*160*320 --> 160*160*320\n",
        "\n",
        "    \"\"\" d1 \"\"\"\n",
        "    e1_d1 = conv_block(e1, cat_channels, n=1)  # 320*320*64 --> 320*320*64\n",
        "\n",
        "    d2_d1 = tfk.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d2)  # 160*160*320 --> 320*320*320\n",
        "    d2_d1 = conv_block(d2_d1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d3_d1 = tfk.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d3)  # 80*80*320 --> 320*320*320\n",
        "    d3_d1 = conv_block(d3_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d4_d1 = tfk.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(d4)  # 40*40*320 --> 320*320*320\n",
        "    d4_d1 = conv_block(d4_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    e5_d1 = tfk.layers.UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)  # 20*20*320 --> 320*320*320\n",
        "    e5_d1 = conv_block(e5_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d1 = tfk.layers.concatenate([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1, ])\n",
        "    d1 = conv_block(d1, upsample_channels, n=1)  # 320*320*320 --> 320*320*320\n",
        "\n",
        "    # last layer does not have batchnorm and relu\n",
        "    d = conv_block(d1, output_channels, n=1, is_bn=False, is_relu=False)\n",
        "\n",
        "    output = tfk.activations.softmax(d)\n",
        "\n",
        "    return tf.keras.Model(inputs=input_layer, outputs=[output], name='UNet_3Plus')\n",
        "\n",
        "\n",
        "model = unet3plus((IMG_SIZE, IMG_SIZE, 2), 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "Tnm4cQ2qmF1E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHzbJ3n6qwVg"
      },
      "outputs": [],
      "source": [
        "class NiiDatasetLoader:\n",
        "    def __init__(self, preprocessors=None):\n",
        "        # store the image preprocessor\n",
        "        self.preprocessors = preprocessors\n",
        "\n",
        "        # if the preprocessors are None, initialize them as an\n",
        "        # empty list\n",
        "        if self.preprocessors is None:\n",
        "            self.preprocessors = []\n",
        "\n",
        "    def load(self, data_folder, modalities):\n",
        "        # initialize the list of features and labels\n",
        "        data = []\n",
        "        labels = []\n",
        "        for folder in sorted(glob.glob(os.path.join(data_folder, \"*\"))):\n",
        "            # show an update info\n",
        "            print('[INFO] Processing foder: ' + folder)\n",
        "            img = []\n",
        "            for modality in modalities:\n",
        "                filename = glob.glob(os.path.join(folder, '*%s*.nii' % modality))[0]\n",
        "                image = nib.load(filename).get_fdata()\n",
        "                # check to see if our preprocessors are not None\n",
        "                if self.preprocessors is not None:\n",
        "                    # loop over the preprocessors and apply each to the image\n",
        "                    for p in self.preprocessors:\n",
        "                        image = p.preprocess(image)\n",
        "                img.append(image)\n",
        "            data.append(np.array(img))\n",
        "            filename = glob.glob(os.path.join(folder, '*seg*.nii'))\n",
        "            if filename == []:\n",
        "                label = None\n",
        "            else:\n",
        "                label= nib.load(filename[0]).get_fdata()\n",
        "                # check to see if our preprocessors are not None\n",
        "                if self.preprocessors is not None:\n",
        "                    # loop over the preprocessors and apply each to the image\n",
        "                    for p in self.preprocessors:\n",
        "                        label = p.preprocess(label)\n",
        "                label = np.expand_dims(label, axis=0)\n",
        "            labels.append(np.array(label))\n",
        "        return (data, labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(data, labels) = NiiDatasetLoader(preprocessor).load(config[\"data_folder\"], config[\"modalities\"])"
      ],
      "metadata": {
        "id": "Wd79lLqXnFof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "-CTFY-ejmyR1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iCM66GlMGTW"
      },
      "outputs": [],
      "source": [
        "csv_logger = CSVLogger('training_20.log', separator=',', append=False)\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1),\n",
        "\n",
        "        csv_logger\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMnDdiH5qwVh"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = [dice_coef])\n",
        "# Evaluate the model on the test data using `evaluate`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvmL9LH9xOpG",
        "outputId": "242bc3b2-1341-487b-90b0-865943da2e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        }
      ],
      "source": [
        "K.clear_session()\n",
        "model.fit(\n",
        "    training_generator,\n",
        "    epochs=200,\n",
        "    steps_per_epoch=len(train_ids),\n",
        "    batch_size=8,\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E291fSDcLVG"
      },
      "outputs": [],
      "source": [
        "model.save(\"200epochsUNET3+112.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 5379620,
          "sourceId": 8940650,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}